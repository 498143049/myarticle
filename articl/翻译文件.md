---
title: 翻译文件
tags: 翻译
grammar_cjkRuby: true
---
# 移动机器人定位
## 7.1 介绍
本章介绍了一些用于移动机器人定位的概率算法。移动机器人定位问题是确定机器人相对于给定的环境地图的姿态。 它通常被称为位置估计或位置跟踪。 移动机器人定位是一般定位性问题，这属于机器人技术中最基本的感知问题。 这是因为几乎所有的机器人任务都需要知道机器人的位置和被操作的物体（虽然不一定在全球地图内）。
定位可以看作是坐标变换问题的一种。 在全局坐标系中，描述地图是和机器人的姿态不相关。定位是将地图坐标和机器人局部坐标建立联系的程序。 了解这个坐标变换使机器人能够表示感兴趣对象在机器人坐标系中的位置 - 机器人导航的必要先决条件。 正如读者容易验证，知道机器人的姿态`!$ \Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt\,. $`足以确定坐标变换，假设姿势在同一坐标系上表示，比如说全局地图。
不幸的是，这里存在移动机器人定位的问题是因为姿态通常不能直接检测。 换句话说，大多数机器人不具备（无噪音！）的传感器用于测量姿态。 因此，姿态将从数据推断出来。 一个关键的难点在于单个传感器测量通常不足确定姿势。而是，机器人必须随着时间的推移数据集来确定其姿态。 为了说明为什么这是必要的，仅仅画出机器人位于有相似长廊的建筑物中。 这里单个传感器测量（例如，范围扫描）通常不足以消除走廊的身份。
定位已经应用于协同广阔地图表。我们已经在前一章讨论了两种类型的地图：基于特征的和基于位置。其中的后者是占用网格图，这个在之后的章节进行讨论。实例地图如图7.1所示。该图显示了手绘度量的二维图，图形拓扑图和图像镶嵌的单元（也可以作为地图）。当代研究中图表示的空间是巨大。一个后续章节将研究具体的地图类型并讨论从数据获取地图的算法。定位的假定前提是准确的地图。

在这个和随后的章节中，我们将介绍一些基本的概率算法的移动定位。 所有这些算法都是基于第2章中描述的贝叶斯滤波器的变体。我们将讨论每个表达式和相关算法的优点和缺点。 本章还通过一系列扩展来解决不同的定位问题，如通过以下机器人定位问题的分类法定义的。

## 7.2 定位的分类

并不是每一个定位问题都有相等的难度。 要理解一个定位问题的难度，我们现在讨论定位问题的简要分类。 这种分类法将通过维度进行划分，这个附属于自然环境，而且是机器人处理定位问题的初初始知识。

### 局部和全局定位
定位问题的特征是在于最初和运行时可用的参数种类。 我们区分三种类别的定位(递增的顺序依次变难)。

+ 位置跟踪 位置跟踪假定初始机器人姿态是已知的。可以通过在机器人运动中适应噪声来实现机器人的定位。这种噪声的影响通常很小。 因此，位置跟踪的方法通常依赖于姿态误差小的假设。 姿态不确定度通常由单峰分布近似（例如，高斯）。 位置跟踪问题是一个局部问题，因为不确定性是局部的，局限于机器人真实姿势附近的区域。
+ 全局定位问题。 这里机器人的初始姿态是未知的。 机器人最初放置在其环境中的某个地方，但缺乏在哪里的信息。 全球定位的方法不能假定姿态误差上限。 正如我们在本章将看到的，单峰概率分布是通常不合适。 全球定位比位置跟踪更难;事实上，它包含了位置跟踪问题。
+ 绑架机器人问题。 这个问题是全球定位问题的一个变体，但更难。 在操作过程中，机器人可以被绑架并移动到另一个位置。 绑架机器人问题比全球本地化问题更困难，因为机器人可能相信它知道它不在哪里。 在世界定位中，有机器人知道它不知道它在哪里。 人们可能会认为机器人很少在实践中被绑架。但是问题出现了确实很重要。 从大多数最先进的定位算法都无法保证永远不会失败。 从故障中恢复的能力至关重要的。自主机器人通过绑架测试定位化算法从全局定位故障中恢复的能力。

### 静态和动态环境
环境是第二个方面使定位问题变难，环境可以是静态或动态的。
+ 静态环境。静态环境是唯一可变量（状态）是机器人姿态。换句话说，只有机器人才能周旋于静态环境。环境中的所有其他物体永远保持在相同的位置。静态环境有一些很好的数学属性，使它们适合于有效的概率估计。
+ 动态环境。动态环境拥有除位置或配置随时间变化的机器人以外的对象。特别感兴趣的是随着时间的推移而持续的变化，而不仅仅是一个传感器的影响。不可衡量的变化当然与定位无关，仅影响单一测量的变化最好被视为噪声（参见第2.4.4节）。更持久变化的例子有：人，日光（适用于配有摄像机的机器人），可移动家具或门。显然，最真实的环境是动态的，状态变化发生在不同速度的范围。

显然，在动态环境中比静态定位更为困难。适应动态有两种主要的方法：首先，动态实体可能被包含在状态向量中。因此，证明马尔科夫假设可以满足，但是这种方法带来额外的计算和建模复杂性的负担;实际上，所得到的算法是有效的映射算法。第二，在某些情况下，传感器数据可以被过滤，以消除未建模动力学的破坏性影响。以下将在第8.4节中进一步描述这种方法。

### 被动与主动方法
第三个描述定位问题是定位算法是或否会控制机器人运动
我们区分２种情况
+ 被动定位，在被动方法中，定位模块仅观察机器人的操作。机器人通过其他手段进行控制，机器人的运动不是为了促定位。例如，机器人可能随机移动或执行其日常任务。
+ 主动定位。主动定位算法控制机器人，以便最小化定位错误和将定位的机器人移动到危险场所所产生的成本。

主动的定位方法通常比被动定位的结果更好。我们已经在本书的介绍中讨论了一些例子：沿海导航。第二个例子如图7.2所示。在这里，机器人位于对称的走廊中，并且在走廊走过一段以两个（对称）姿势为中心的时间之后。环境的局部对称使得在走廊中不可能使机器人定位。只有当它进入房间时，才能消除歧义并确定其姿态。像这样的情况，主动定位算法给出更好的结果：而不是只等到机器人顺利移动到一个房间，主动定位可以识别出来并直接发送到它。
然而，主动方法的一个主要限制是它们需要控制机器人。 因此，在实践中，单独的主动定位技术往往是不够的：机器人必须能够自己进行定位，即使在执行一些比定位更重要的任务。 一些积极的定位技术是建立在一被动定位技术之上的。当控制机器人的时候，其他人将的任务性能目标与定位目标相结合。

本章专门讨论被动定位算法。 我们将回到本书第？章中的主动定位问题，我们将介绍机器人控制的概率算法。

### 单机器人和多机器人
第四个定位问题是和机器人的数目有关。
+ Single-robot localization. The most commonly studied approach to localization deals with a single robot only. Single robot localization offers the convenience that all data is collected at a single robot platform, and there is no communication issue.
+ 单机器人定位 最常用的研究方法是仅针对单个机器人。 单机器人定位提供了在单个机器人平台上收集所有数据的便利性，并且没有通信问题。

+ Multi-robot localization. The localization problem naturally arises to teams of robots. At first glance, each robot could localize itself individually, hence the multi-robot localization problem can be solved through single-robot localization. If robots are able to detect each other, however, there is the opportunity to do better. This is because one robot’s belief can be used to bias another robot’s belief if knowledge of the relative location of both robots is available. The issue of multi-robot localization raises interesting, non-trivial issues on the representation of beliefs and the nature of the communication between them.
+ 多机器人定位 机器人团队自然会出现定位问题。 乍一看，每个机器人可以单独定位，因此多机器人定位问题可以通过单机器人定位来解决。 然而，如果机器人能够相互检测，则有机会做得更好。 这是因为如果有两个机器人的相对位置的知识可用，一个机器人的知识可以用于偏向另一个机器人的知识。 多机器人定位的问题的提出是非常有趣的，重要的问题在他们代表的想法和他们之间最自然的通信。

These four dimensions capture the four most important characteristics of the mobile robot localization problem. There exist a number of other characterizations that impact the hardness of the problem, such as the information provided by robot measurements and the information lost through motion. Also, symmetric environments are more difficult than asymmetric ones, due to the higher degree of ambiguity. We will now look at specific algorithms and discuss their applicability to the different localization problems as defined thus far

这四个方向捕获移动机器人定位问题的四个最重要的特征。存在其他一些特征影响着问题难度的，比如需要运动机器测量值和运动信息丢失的问题。此外，由于较高程度的不确定性，对称环境比非对称环境更困难。 现在，我们将着眼于特定的算法，并讨论其适用于不同的定位问题。

### MARKOV LOCALIZATION
###　markov定位

Probabilistic localization algorithms are variants of the Bayes filter. The straight forward application of Bayes filters to the localization problem is called Markov localization.Table 7.1 depicts the basic algorithm. This algorithm is derived from the algorithm Bayes filter (Table 2.1 on page 24). Notice that Markov localization also requires a map m as input. The map plays a role in the measurement model p(zt j xt;m) (Line 4). It often, but not always, is incorporated in the motion model p(xt j ut; xt􀀀1;m) as well (Line 3). Just like the Bayes filter, Markov localization transforms a probabilistic belief at time t 􀀀 1 into a belief at time t. Markov localization addresses the global localization problem, the position tracking problem, and the kidnapped robot problem in static environments. The initial belief, bel(x0), reflects the initial knowledge of the robot’s pose. It is set differently depending on the type of localization problem.
概率定位算法是贝叶斯滤波器的变体。直接使用贝叶斯滤波器解决定位问题，这称为马尔可夫定位。马可夫定位，表7.1描述了其基本的算法。该算法是从贝叶斯滤波算法得到的（第24页的表2.1）。请注意，马可夫定位还需要一个地图m作为输入。map的作用是用测量模型， 他通常但是不总是包含于运动模型。正如贝叶斯滤波器，马尔可夫定位将时间t-1的概率信念转化为时间t的信念。 马可夫定位解决了全球定位问题，位置跟踪问题，以及在静态环境中绑架的机器人问题。
最初的信念bel（x0）反映了机器人初始姿态 它根据定位问题的类型而有所不同。

+ Position tracking. If the initial pose is known, bel(x0) is initialized by a point mass distribution. Let x0 denote the (known) initial pose. Then

+ 位置跟踪 如果已知初始姿态，则bel（x0）由点质量分布进行初始化。 令x0表示（已知）初始姿态。 则
  $$

+ Point-mass distributions are discrete and therefore do not possess a density. In practice the initial pose is often just known in approximation. The belief bel(x0) is then usually initialized by a narrow Gaussian distribution centered around x0. Gaussians were defined in Equation (2.4) on page 11.

+ 点质量分布是离散的，因此不具有密度。 在实践中，通常初始已知近似的姿态。 通常bel(x0) 通常由窄宽带，以x0位中心的高斯分布初始化。高斯函数可以由11页的等式2,4所定义。


+ Global localization. If the initial pose is unknown, bel(x0) is initialized by a uniform distribution over the space of all legal poses in the map:

+ 全球定位。 如果初始姿势未知，则使用在地图所有的合法位置使用均匀分布对bel（x0）进行初始化：

+ Other. Partial knowledge of the robot’s position can usually easily be transformed into an appropriate initial distribution. For example, if the robot is known to start next to a door, one might initialize bel(x0) using a density that is zero except for places near doors, where it may be uniform. If it is known to be located in a specific corridor, one might initialize bel(x0) by a uniform distribution in the area of the corridor and zero anywhere else.

+ 其他。 机器人位置的部分知识通常可以很容易地转化为适当的初始分布。 例如，如果知道机器人在门旁边开始，则可以使用密度为零的bel（x0）初始化，除了靠近门的地方，其他地方都是均匀的。 如果知道位于特定的走廊，则可以通过在走廊区域中的均匀分布来初始化bel（x0），而在其他任何地方给零。


### ILLUSTRATION OF MARKOV LOCALIZATION
### MARKOV定位图示

We have already discussed Markov localization in the introduction to this book, as a motivating example for probabilistic robotics. Now we can back up this example using a concrete mathematical framework. Figure 7.3 depicts our one-dimensional hallway with three identically looking doors. The initial belief bel(x0) is uniform over all poses, as illustrated by the uniform density in Figure 7.4a. As the robot queries its sensors and notices that it is adjacent to one of the doors, it multiplies its belief bel(x0) by p(zt j xt;m), as stated in Line 4 of our algorithm. The upper density in Figure 7.4b visualizes p(zt j xt;m) for the hallway example. The lower density is the result of multiplying this density into the robot’s uniform prior belief. Again, the resulting belief is multi-modal, reflecting the residual uncertainty of the robot at this point.

我们已经在本书的介绍中讨论了马尔可夫定位，作为概率机器人的启发式例子。 现在我们可以使用具体的数学框架来回顾这个例子。 图7.3描绘了我们的一维走廊，有三个相同的门。 最初的信念bel（x0）在所有姿态中均匀分布，如图7.4a中的均匀密度所示。 当机器人查询其传感器并注意到它与其中一个门相邻时，它将其信念bel（x0）乘以p（zt j xt; m），如我们的算法的第4行所述。 图7.4b中的高密度可视化走廊示例的p（zt j xt; m）。 较低的密度是将该密度乘以机器人先前信念的结果。 再次，由此产生的信念是多模式的，这反映了这一点上机器人不确定性的残余。

+ As the robot moves to the right, indicated in Figure 7.4c, Line 3 of the Markov locations algorithm convolves its belief with the motion model p(xt j ut; xt􀀀1). The motion model p(xt j ut; xt􀀀1) is not focused on a single pose but on a whole continuum of poses centered around the expected outcome of a noise-free motion. The effect is visualized in Figure 7.4c, which shows a shifted belief that is also flattened out, as a result of the convolution.

+ 当机器人向右移动时，如图7.4c所示，马尔科夫位置算法的第3行将其信念与运动模型p（xt j ut;xt􀀀1）进行卷积。 运动模型p（xt j ut;xt􀀀1）不是集中在单个姿势上，而是假定无噪声运动下，整个连续姿态的预期结果。该效果如图7.4c中所示，其显示了由于卷积而使信念也被平坦化。

po
The final measurement is illustrated in Figure 7.4d. Here the Markov localization algorithm multiplies the current belief with the perceptual probability p(zt j xt). At this point, most of the probability mass is focused on the correct pose, and the robot is quite confident of having localized itself. Figure 7.4e illustrates the robot’s belief after having moved further down the hallway.

最终测量如图7.4d所示。 这里，马尔可夫定位算法将当前信念与感知概率p（zt j xt）相乘。在这一点上，大多数概率都集中在正确的位姿上，机器人本身就确信自己的定位。 图7.4e说明了机器人沿着走廊进一步移动后的信念。


We already noted that Markov localization is independent of the underlying representation of the state space. In fact, Markov localization can be implemented using any of the representations discussed in Chapter 2. We will now consider three different representations and devise practical algorithms that can localize mobile robots in real time. We begin with Kalman filters, which represent beliefs by their first and second moment. We then continue with discrete, grid representations and finally introduce algorithms using particle filters.

我们已经注意到马尔可夫定位是独立于状态空间的下的表达。事实上，马可夫本定位可以使用第2章中讨论的任何表述来实现。 我们现在将考虑三种不同的表示方式，并设计在实际中可实时定位移动机器人的算法。 我们从卡尔曼滤波器开始，用它来表示第一和第二时刻代表信念。然后，我们继续使用离散的网格表示，最后引入使用粒子滤波器的算法。

###  EKF LOCALIZATION中种
###  EKF 定位
The extended Kalman filter localization algorithm, or EKF localization, is a special case of Markov localization. EKF localization represent beliefs $bel(x_1)$ by their their first and second moment, that is, the mean $\mu_t$ and the covariance $\Sigma_t$. The basic EKF algorithm was stated in Table 3.3 in Chapter 3.3. EKF localization shall be our first concrete implementation of an EKF in the context of an actual robotics problem.

扩展卡尔曼滤波器定位算法或EKF定位是马尔科夫定位的一个特例。 EKF定位通过他们的第一和第二时刻代表信念$ bel（x_1）$，即平均值$ \ mu_t $和协方差$ \ Sigma_t $。 第3.3章表3.3中列出了基本的EKF算法。在实际机器人问题中， EKF定位是EKF算法的第一个实现。

Our EKF localization algorithm assumes that the map is represented by a collectionof features. Thus, at any point in time t, the robot gets to observe a vector of rangesand bearings to nearby features: $z_1=\{z_t^1,z_t^1,\dots\}$ We begin with a localization algorithm in which all features are uniquely identiﬁable. The existence of uniquely identiﬁable features may not be a bad assumption: For example, the Eiffel Tour inParis is a landmark that is rarely confused with other landmarks, and it is widely visible throughout Paris. The identity of a feature is expressed by set of correspondence variables, denoted $c^i_t$, one for each feature vector $z^i_t$. Correspondence variables werealready discussed in Chapter 6.6. In our ﬁrst algorithm, the correspondence is assumed to be known. We then progress to a more general version which allows for ambiguity among features. Instead of the correspondence, the robot observes a feature signature,$s^i_t$ . The second, more general version applied a maximum likelihood estimator to estimate the value of the latent correspondence variable, and uses the result of thisestimation as ground truth

我们的EKF定位算法假定地图由一组特征集合表示。因此，在任何时间点t，机器人都可以观察到附近特征的范围和方位向量：$ z_1 = \ {z_t ^ 1，z_t ^ 1，\ dots \} $我们从定位算法开始，其中特征是独一无二而且可识别的，独一无二的特征将不会有不好的假设。例如，巴黎的埃菲尔忒他是一个地标，很少与其他地标混淆，在巴黎经常可见。特征可以由对应变量集合表示，表示为$ c ^ i_t $，每个特征向量由$ z ^ i_t $表示。第6.6章讨论了函数变量。在我们的第一个算法中，假设对应关系是已知的。之后，我们扩展到更一般的情况，比如允许一些不确定的特征。除一致性以外，而是观察特征签名$ s ^ i_t $。第二个更一般的版本应用最大似然估计器来估计潜在对应变量的值，并将该估计的结果用作基本的真实值。


### Illustration
























